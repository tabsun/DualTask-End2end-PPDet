pretrain_weights: output/picodet_l_640_xd_lcnet_bak/best_model.pdparams
slim: QAT

QAT:
  quant_config: {
    'activation_preprocess_type': 'PACT',
    'weight_quantize_type': 'channel_wise_abs_max', 'activation_quantize_type': 'moving_average_abs_max',
    'weight_bits': 8, 'activation_bits': 8, 'dtype': 'int8', 'window_size': 10000, 'moving_rate': 0.9,
    'quantizable_layer_type': ['Conv2D', 'Linear']}
  print_model: False

TrainReader:
  batch_size: 2

LearningRate:
  base_lr: 0.008
  schedulers:
  - !CosineDecay
    max_epochs: 60
  - !LinearWarmup
    start_factor: 0.1
    steps: 60
