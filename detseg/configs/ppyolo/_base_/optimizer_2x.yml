epoch: 12

LearningRate:
  base_lr: 2e-5
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones:
    - 8
    - 11
  - !LinearWarmup
    start_factor: 0.
    steps: 100

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0005
    type: L2
